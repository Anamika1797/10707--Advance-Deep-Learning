{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9e91f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dbn import DBN, fit_mnist_dbn\n",
    "from neural_net import WarmUpMLPClassifier\n",
    "from rbm import RBM, binary_data, shuffle_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edc56d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_net import WarmUpMLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303c1a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_net import WarmUpMLPClassifier as ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9da77fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, path = None, cols=3, cmap='gray'):\n",
    "    rows = (len(images) + cols - 1) // cols\n",
    "    fig, ax = plt.subplots(rows, cols)\n",
    "    for i, image in enumerate(images):\n",
    "        ax[i//cols][i%cols].imshow(image, cmap=cmap)\n",
    "        ax[i//cols][i%cols].get_xaxis().set_ticks([])\n",
    "        ax[i//cols][i%cols].get_yaxis().set_ticks([])\n",
    "    for i in range(len(images), rows*cols):\n",
    "        ax[i//cols][i%cols].get_xaxis().set_ticks([])\n",
    "        ax[i//cols][i%cols].get_yaxis().set_ticks([])\n",
    "        ax[i//cols][i%cols].axis('off')\n",
    "    fig.set_size_inches(cols*10, rows*10)\n",
    "    if path is not None:\n",
    "        plt.savefig(path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8c58adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(all='raise')\n",
    "train_data = np.genfromtxt('./data/digitstrain.txt', delimiter=\",\")\n",
    "train_X = train_data[:, :-1] \n",
    "train_Y = train_data[:, -1]\n",
    "train_X = binary_data(train_X)\n",
    "\n",
    "valid_data = np.genfromtxt('./data/digitsvalid.txt', delimiter=\",\")\n",
    "valid_X = valid_data[:, :-1]\n",
    "valid_X = binary_data(valid_X)\n",
    "valid_Y = valid_data[:, -1]\n",
    "\n",
    "test_data = np.genfromtxt('./data/digitstest.txt', delimiter=\",\")\n",
    "test_X = test_data[:, :-1]\n",
    "test_X = binary_data(test_X)\n",
    "test_Y = test_data[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd37082e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 :: \t Train Error 8.7598                   :: Valid Error 8.8131\n",
      "Epoch 2 :: \t Train Error 8.1627                   :: Valid Error 8.3067\n",
      "Epoch 3 :: \t Train Error 7.8203                   :: Valid Error 7.9549\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([8.759829257076378, 8.162687339213615, 7.820300377181146],\n",
       " [8.813050977691502, 8.306656304345573, 7.954921829892659])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbm = RBM(n_visible=784, n_hidden=100,  k=1, lr=0.01, max_epochs=3)\n",
    "rbm.fit(X=train_X, valid_X=valid_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656d7bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm.hbias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2228ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3313ca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm_clf.coefs_[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5db3e75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a63736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0b4c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43b0ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864b7f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ws=[rbm.W,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cc0fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54088714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n",
      "Complete happy\n",
      "Iteration 1, loss = 1.45204662\n",
      "Iteration 2, loss = 1.26494080\n"
     ]
    },
    {
     "ename": "FloatingPointError",
     "evalue": "underflow encountered in multiply",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-1141eb5a6529>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                                \u001b[0mhidden_layer_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                Ws=[rbm.W,], hbiases=[rbm.hbias,])\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mrbm_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrbm_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_curve_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anamika\\Python\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mMLP\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m         \"\"\"\n\u001b[1;32m--> 673\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anamika\\Python\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[1;31m# Run the Stochastic optimization solver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_STOCHASTIC_SOLVERS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m             self._fit_stochastic(X, y, activations, deltas, coef_grads,\n\u001b[0m\u001b[0;32m    400\u001b[0m                                  intercept_grads, layer_units, incremental)\n\u001b[0;32m    401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anamika\\Python\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit_stochastic\u001b[1;34m(self, X, y, activations, deltas, coef_grads, intercept_grads, layer_units, incremental)\u001b[0m\n\u001b[0;32m    571\u001b[0m                     \u001b[1;31m# update weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m                     \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoef_grads\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mintercept_grads\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anamika\\Python\\lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py\u001b[0m in \u001b[0;36mupdate_params\u001b[1;34m(self, grads)\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mSo\u001b[0m \u001b[0mlength\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0maligned\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \"\"\"\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mupdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_updates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdate\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mparam\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anamika\\Python\\lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py\u001b[0m in \u001b[0;36m_get_updates\u001b[1;34m(self, grads)\u001b[0m\n\u001b[0;32m    261\u001b[0m         self.ms = [self.beta_1 * m + (1 - self.beta_1) * grad\n\u001b[0;32m    262\u001b[0m                    for m, grad in zip(self.ms, grads)]\n\u001b[1;32m--> 263\u001b[1;33m         self.vs = [self.beta_2 * v + (1 - self.beta_2) * (grad ** 2)\n\u001b[0m\u001b[0;32m    264\u001b[0m                    for v, grad in zip(self.vs, grads)]\n\u001b[0;32m    265\u001b[0m         self.learning_rate = (self.learning_rate_init *\n",
      "\u001b[1;32mC:\\Anamika\\Python\\lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    261\u001b[0m         self.ms = [self.beta_1 * m + (1 - self.beta_1) * grad\n\u001b[0;32m    262\u001b[0m                    for m, grad in zip(self.ms, grads)]\n\u001b[1;32m--> 263\u001b[1;33m         self.vs = [self.beta_2 * v + (1 - self.beta_2) * (grad ** 2)\n\u001b[0m\u001b[0;32m    264\u001b[0m                    for v, grad in zip(self.vs, grads)]\n\u001b[0;32m    265\u001b[0m         self.learning_rate = (self.learning_rate_init *\n",
      "\u001b[1;31mFloatingPointError\u001b[0m: underflow encountered in multiply"
     ]
    }
   ],
   "source": [
    "rbm_clf = WarmUpMLPClassifier(lr=0.01, max_epochs=50, \n",
    "                               hidden_layer_sizes=(100,),\n",
    "                               Ws=[rbm.W,], hbiases=[rbm.hbias,])\n",
    "rbm_clf.fit(train_X, train_Y)\n",
    "\n",
    "plt.plot(rbm_clf.loss_curve_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7fa7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm_clf_without = WarmUpMLPClassifier(lr=0.01, max_epochs=50, \n",
    "                               hidden_layer_sizes=(100,),\n",
    "                               Ws=None, hbiases=None)\n",
    "rbm_clf_without.fit(train_X, train_Y)\n",
    "\n",
    "plt.plot(rbm_clf_without.loss_curve_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0de9ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
